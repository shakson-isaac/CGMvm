{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74f120c",
   "metadata": {},
   "source": [
    "## Trying multiple SOTA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911420a",
   "metadata": {},
   "source": [
    "### I FORGOT to install mlforecast!!! ugh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da742ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to '/n/groups/patel/shakson/aiready/'\n",
    "import os\n",
    "os.chdir(\"/home/shaksonisaac/CGM/mambatf/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f3c1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD Datasets\n",
    "import pandas as pd\n",
    "import io\n",
    "from google.cloud import storage\n",
    "\n",
    "_BUCKET_NAME = \"cgmproject2025\"\n",
    "\n",
    "# Download dataset from GCS\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(_BUCKET_NAME)\n",
    "blob = bucket.blob('ai-ready/data/train_timeseries_meal.feather')\n",
    "data_bytes = blob.download_as_bytes()\n",
    "train = pd.read_feather(io.BytesIO(data_bytes))\n",
    "\n",
    "\n",
    "# Download test set:\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(_BUCKET_NAME)\n",
    "blob = bucket.blob('ai-ready/data/test_timeseries_meal.feather')\n",
    "data_bytes = blob.download_as_bytes()\n",
    "test = pd.read_feather(io.BytesIO(data_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "318f89fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>cgm_glucose</th>\n",
       "      <th>activity_steps</th>\n",
       "      <th>calories_value</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>respiration_rate</th>\n",
       "      <th>sleep_stage</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>...</th>\n",
       "      <th>cgm_diff_lag_3</th>\n",
       "      <th>cgm_diff_lag_6</th>\n",
       "      <th>cgm_lagdiff_1_3</th>\n",
       "      <th>cgm_lagdiff_3_6</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>tod_sin</th>\n",
       "      <th>tod_cos</th>\n",
       "      <th>cgm_rolling_mean</th>\n",
       "      <th>cgm_rolling_std</th>\n",
       "      <th>predmeal_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1023</td>\n",
       "      <td>2023-08-30 18:45:00+00:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.946</td>\n",
       "      <td>light</td>\n",
       "      <td>43.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.237686</td>\n",
       "      <td>0.971342</td>\n",
       "      <td>118.166667</td>\n",
       "      <td>16.336425</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1023</td>\n",
       "      <td>2023-08-30 18:50:00+00:00</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>14.588</td>\n",
       "      <td>light</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>114.916667</td>\n",
       "      <td>16.983727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1023</td>\n",
       "      <td>2023-08-30 18:55:00+00:00</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>15.262</td>\n",
       "      <td>light</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.279829</td>\n",
       "      <td>0.960050</td>\n",
       "      <td>111.250000</td>\n",
       "      <td>16.526150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1023</td>\n",
       "      <td>2023-08-30 19:00:00+00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>83.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.640</td>\n",
       "      <td>light</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.300706</td>\n",
       "      <td>0.953717</td>\n",
       "      <td>107.416667</td>\n",
       "      <td>14.164349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1023</td>\n",
       "      <td>2023-08-30 19:05:00+00:00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>light</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.321439</td>\n",
       "      <td>0.946930</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>10.991732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id                        ts  cgm_glucose  activity_steps  \\\n",
       "11           1023 2023-08-30 18:45:00+00:00        101.0             0.0   \n",
       "12           1023 2023-08-30 18:50:00+00:00         94.0             0.0   \n",
       "13           1023 2023-08-30 18:55:00+00:00         93.0             0.0   \n",
       "14           1023 2023-08-30 19:00:00+00:00         95.0           102.0   \n",
       "15           1023 2023-08-30 19:05:00+00:00        101.0           102.0   \n",
       "\n",
       "    calories_value  heartrate  oxygen_saturation  respiration_rate  \\\n",
       "11             4.0       81.0               93.0            10.946   \n",
       "12             4.0       77.0               93.0            14.588   \n",
       "13             4.0       77.0               93.0            15.262   \n",
       "14             4.0       83.6               93.0             2.640   \n",
       "15             4.0       90.4               93.0            -1.000   \n",
       "\n",
       "   sleep_stage  stress_level  ...  cgm_diff_lag_3 cgm_diff_lag_6  \\\n",
       "11       light          43.2  ...            -1.0          -20.0   \n",
       "12       light          -1.0  ...           -11.0          -18.0   \n",
       "13       light           6.8  ...            -9.0           -6.0   \n",
       "14       light           6.6  ...            -6.0           -7.0   \n",
       "15       light          -2.0  ...             7.0           -4.0   \n",
       "\n",
       "   cgm_lagdiff_1_3  cgm_lagdiff_3_6  minute_of_day   tod_sin   tod_cos  \\\n",
       "11             0.0            -19.0             55  0.237686  0.971342   \n",
       "12            -4.0             -7.0             60  0.258819  0.965926   \n",
       "13            -8.0              3.0             65  0.279829  0.960050   \n",
       "14            -8.0             -1.0             70  0.300706  0.953717   \n",
       "15             1.0            -11.0             75  0.321439  0.946930   \n",
       "\n",
       "    cgm_rolling_mean  cgm_rolling_std  predmeal_flag  \n",
       "11        118.166667        16.336425            0.0  \n",
       "12        114.916667        16.983727            0.0  \n",
       "13        111.250000        16.526150            0.0  \n",
       "14        107.416667        14.164349            0.0  \n",
       "15        104.500000        10.991732            0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7adb6820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participant_id', 'ts', 'cgm_glucose', 'activity_steps',\n",
       "       'calories_value', 'heartrate', 'oxygen_saturation', 'respiration_rate',\n",
       "       'sleep_stage', 'stress_level', 'ds', 'clinical_site', 'study_group',\n",
       "       'age', 'cgm_lag_1', 'cgm_lag_3', 'cgm_lag_6', 'cgm_diff_lag_1',\n",
       "       'cgm_diff_lag_3', 'cgm_diff_lag_6', 'cgm_lagdiff_1_3',\n",
       "       'cgm_lagdiff_3_6', 'minute_of_day', 'tod_sin', 'tod_cos',\n",
       "       'cgm_rolling_mean', 'cgm_rolling_std', 'predmeal_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16541864",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlforecast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlforecast\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlforecast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLForecast\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlforecast'"
     ]
    }
   ],
   "source": [
    "# import mlforecast\n",
    "# from mlforecast import MLForecast\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from mlforecast.utils import PredictionIntervals\n",
    "# from mlforecast.lag_transforms import RollingMean, ExpandingStd, ExpandingMean\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# CATEGORICAL_COLS = [\"participant_id\", \"clinical_site\", \"study_group\", \"sleep_stage\"]\n",
    "\n",
    "# # 1) Feature‐engineer once\n",
    "# df = create_features(train.copy())\n",
    "# for c in CATEGORICAL_COLS:\n",
    "#     if c in df.columns:\n",
    "#         df[c] = df[c].astype(\"category\")\n",
    "\n",
    "\n",
    "# # Set up the model\n",
    "# fcst = MLForecast(\n",
    "#     models=[LGBMRegressor()],\n",
    "#     freq=1,  # 5-minute intervals\n",
    "#     lags=[1, 2, 3, 6, 12, 18, 24, 36, 48, 72, 96, 144],  # 5min, 10min, 15min, 30min, 1hr, 1.5hr, 2hr, 3hr, 4hr, 6hr, 8hr, 12hr\n",
    "#     lag_transforms = {\n",
    "#     12: [RollingMean(window_size=12)],    # 1-hour average\n",
    "#     24: [RollingMean(window_size=24)],    # 2-hour average\n",
    "#     48: [RollingMean(window_size=48)],    # 4-hour average\n",
    "#     144: [ExpandingMean()]                # trend since start of CGM\n",
    "#     },\n",
    "#     #date_features=[\"hour\",\"dayofweek\"],\n",
    "#     #date_features=['hour', 'dayofweek']\n",
    "# )\n",
    "\n",
    "# # Preprocess training data to include all horizons\n",
    "# # Fit the model with the specified maximum horizon\n",
    "# fcst.fit(\n",
    "#     df=df,\n",
    "#     id_col='participant_id',\n",
    "#     time_col='ds',\n",
    "#     target_col='cgm_glucose',\n",
    "#     static_features=[\"age\", \"participant_id\", \"clinical_site\", \"study_group\"],\n",
    "#     max_horizon=12,  # Forecasting 12 steps ahead\n",
    "#     prediction_intervals=PredictionIntervals(n_windows=10, h=12) # 10 windows of 3 steps each\n",
    "#     #fitted=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8540a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATSx\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "#from mlforecast.utils import PredictionIntervals  # you can still use this for pinball windows if you like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb75ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'participant_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_135555/2551684187.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# --- 4) Fit ------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m nf.fit(\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mstatic_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mval_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# hold out last 12 points per series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, df, static_df, val_size, use_init_models, verbose, id_col, time_col, target_col, distributed_config, prediction_intervals)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Process and save new dataset (in self)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mvalidate_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             self.dataset, self.uids, self.last_dates, self.ds = self._prepare_fit(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mstatic_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mpredict_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, df, static_df, predict_only, id_col, time_col, target_col)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         dataset, uids, last_dates, ds = TimeSeriesDataset.from_df(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mstatic_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/tsdataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, static_df, id_col, time_col, target_col)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unique_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# TODO: protect on equality of static_df + df indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Define indices if not given and then extract static features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         static, static_cols = TimeSeriesDataset._extract_static_features(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/tsdataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(static_df, id_col)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_static_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatic_df\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mstatic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mstatic_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mstatic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstatic_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mstatic_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/utilsforecast/processing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, by)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7192\u001b[0m             )\n\u001b[1;32m   7193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7194\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7196\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7198\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'participant_id'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from neuralforecast import NeuralForecast\n",
    "# from neuralforecast.models import NBEATSx\n",
    "# from neuralforecast.losses.pytorch import MQLoss\n",
    "# #from mlforecast.utils import PredictionIntervals  # you can still use this for pinball windows if you like\n",
    "\n",
    "# # --- 1) Prepare your dynamic panel -------------------------------------------\n",
    "\n",
    "# # rename for NeuralForecast’s expectations\n",
    "# df = (\n",
    "#     train\n",
    "#     .rename(columns={\n",
    "#         \"participant_id\": \"unique_id\",\n",
    "#         \"ds\":             \"ds\",\n",
    "#         \"cgm_glucose\":    \"y\"\n",
    "#     })\n",
    "#     .sort_values([\"unique_id\", \"ds\"])\n",
    "# )\n",
    "\n",
    "# # cast any categoricals\n",
    "# for c in [\"unique_id\", \"clinical_site\", \"study_group\", \"sleep_stage\", \"predmeal_flag\"]:\n",
    "#     if c in df:\n",
    "#         df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# # --- 2) Extract your static covariates ---------------------------------------\n",
    "\n",
    "# static_df = (\n",
    "#     df[[\"unique_id\", \"age\", \"clinical_site\", \"study_group\"]]\n",
    "#     .drop_duplicates()\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "# # --- 3) Define the NBEATSx model --------------------------------------------\n",
    "# model = NBEATSx(\n",
    "#     h=12,                         # forecast 12 steps ahead\n",
    "#     input_size=288,               # how many past points to expose (e.g. 12 hrs = 288 ×5 min)\n",
    "#     loss=MQLoss(quantiles=[0.2, 0.5, 0.8]),   # if you want quantiles\n",
    "#     stat_exog_list=[\"age\", \"clinical_site\", \"study_group\"],\n",
    "#     hist_exog_list=[\n",
    "#       # any time‐varying covariates you only have historically:\n",
    "#       \"cgm_glucose\", \"cgm_lag_1\", \"cgm_lag_3\", \"cgm_lag_6\", \"cgm_diff_lag_1\", \"cgm_diff_lag_3\",\n",
    "#       \"cgm_diff_lag_6\", \"cgm_lagdiff_1_3\", \"cgm_lagdiff_3_6\", \"cgm_rolling_mean\", \"cgm_rolling_std\",\n",
    "#     ],\n",
    "#     futr_exog_list=[\n",
    "#       # covariates you know into the future (e.g. clock features):\n",
    "#       \"minute_of_day\",\"tod_sin\",\"tod_cos\"\n",
    "#     ] + [\n",
    "#       # plus whatever you can project forward (e.g. planned meals flags)\n",
    "#       \"activity_steps\", \"calories_value\", \"heartrate\", \n",
    "#       \"oxygen_saturation\", \"respiration_rate\", \"stress_level\",\n",
    "#       \"predmeal_flag\", \"sleep_stage\"\n",
    "#     ],\n",
    "#     stack_types=[\"identity\",\"trend\",\"seasonality\",\"exogenous\"],\n",
    "#     n_blocks=[1,1,1,1],\n",
    "#     mlp_units=[[512,512]]*4,\n",
    "#     max_steps=1000,\n",
    "#     learning_rate=1e-3,\n",
    "#     early_stop_patience_steps=100\n",
    "# )\n",
    "\n",
    "# nf = NeuralForecast(\n",
    "#     models=[model],\n",
    "#     freq=1   # 5-minute intervals\n",
    "# )\n",
    "\n",
    "# # --- 4) Fit ------------------------------------------------------------------\n",
    "\n",
    "# nf.fit(\n",
    "#     df=train,\n",
    "#     static_df=static_df,\n",
    "#     val_size=12,  # hold out last 12 points per series\n",
    "#     id_col=\"participant_id\",\n",
    "#     time_col=\"ds\",\n",
    "#     target_col=\"cgm_glucose\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654970f",
   "metadata": {},
   "source": [
    "## Model 1: NBEATSx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6176de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "/tmp/ipykernel_135555/342854755.py:76: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135555/342854755.py:76: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n",
      "/tmp/ipykernel_135555/342854755.py:78: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n",
      "/tmp/ipykernel_135555/342854755.py:78: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_id      y  activity_steps  calories_value  heartrate  \\\n",
      "0      1023  101.0             0.0             4.0       81.0   \n",
      "1      1023   94.0             0.0             4.0       77.0   \n",
      "2      1023   93.0             0.0             4.0       77.0   \n",
      "3      1023   95.0           102.0             4.0       83.6   \n",
      "4      1023  101.0           102.0             4.0       90.4   \n",
      "\n",
      "   oxygen_saturation  respiration_rate sleep_stage  stress_level  ds  ...  \\\n",
      "0               93.0            10.946       light          43.2  11  ...   \n",
      "1               93.0            14.588       light          -1.0  12  ...   \n",
      "2               93.0            15.262       light           6.8  13  ...   \n",
      "3               93.0             2.640       light           6.6  14  ...   \n",
      "4               93.0            -1.000       light          -2.0  15  ...   \n",
      "\n",
      "  cgm_diff_lag_3 cgm_diff_lag_6  cgm_lagdiff_1_3  cgm_lagdiff_3_6  \\\n",
      "0           -1.0          -20.0              0.0            -19.0   \n",
      "1          -11.0          -18.0             -4.0             -7.0   \n",
      "2           -9.0           -6.0             -8.0              3.0   \n",
      "3           -6.0           -7.0             -8.0             -1.0   \n",
      "4            7.0           -4.0              1.0            -11.0   \n",
      "\n",
      "   minute_of_day   tod_sin   tod_cos  cgm_rolling_mean  cgm_rolling_std  \\\n",
      "0             55  0.237686  0.971342        118.166667        16.336425   \n",
      "1             60  0.258819  0.965926        114.916667        16.983727   \n",
      "2             65  0.279829  0.960050        111.250000        16.526150   \n",
      "3             70  0.300706  0.953717        107.416667        14.164349   \n",
      "4             75  0.321439  0.946930        104.500000        10.991732   \n",
      "\n",
      "   predmeal_flag  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MQLoss        | 3      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 24.2 M | train\n",
      "-------------------------------------------------------\n",
      "24.2 M    Trainable params\n",
      "7.5 K     Non-trainable params\n",
      "24.2 M    Total params\n",
      "96.738    Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 16/16 [00:02<00:00,  7.48it/s, v_num=58, train_loss_step=14.70, train_loss_epoch=14.00, valid_loss=13.40] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 16/16 [00:02<00:00,  7.47it/s, v_num=58, train_loss_step=14.70, train_loss_epoch=14.00, valid_loss=13.40]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATSx\n",
    "from neuralforecast.losses.pytorch import MQLoss\n",
    "\n",
    "# --- 0) Assume `train` already has:\n",
    "#       • `participant_id` as grouping key\n",
    "#       • `ds` as integer time‐index (0,1,2,3,…)\n",
    "#       • `cgm_glucose` as your target\n",
    "#       • all your hist/futr covariates\n",
    "\n",
    "# --- 1) Rename only the ID & target (leave ds alone!) ----------------------\n",
    "\n",
    "df = (\n",
    "    train\n",
    "    .drop(columns=[\"ts\"])                 # ← get rid of the Timestamp column\n",
    "    .rename(columns={\n",
    "        \"participant_id\": \"unique_id\",  # NF’s default group key\n",
    "        \"cgm_glucose\":    \"y\"           # NF’s default target\n",
    "    })\n",
    "    .sort_values([\"unique_id\", \"ds\"])\n",
    ")\n",
    "\n",
    "# --- 2) Cast categoricals --------------------------------------------------\n",
    "\n",
    "for c in [\"unique_id\", \"clinical_site\", \"study_group\", \"sleep_stage\", \"predmeal_flag\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# --- 3) Build static_df on unique_id ----------------------------------------\n",
    "\n",
    "static_df = (\n",
    "    df[[\"unique_id\", \"age\", \"clinical_site\", \"study_group\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --- 4) Define your NBEATSx model (same as before) --------------------------\n",
    "\n",
    "model = NBEATSx(\n",
    "    h=12,\n",
    "    input_size=288,\n",
    "    loss=MQLoss(quantiles=[0.2, 0.5, 0.8]),\n",
    "    stat_exog_list=[\"age\", \"clinical_site\", \"study_group\"],\n",
    "    hist_exog_list=[\n",
    "        \"cgm_lag_1\",\"cgm_lag_3\",\"cgm_lag_6\",\n",
    "        \"cgm_diff_lag_1\",\"cgm_diff_lag_3\",\"cgm_diff_lag_6\",\n",
    "        \"cgm_lagdiff_1_3\",\"cgm_lagdiff_3_6\",\n",
    "        \"cgm_rolling_mean\",\"cgm_rolling_std\",\n",
    "        \"activity_steps\",\"calories_value\",\"heartrate\",\n",
    "        \"oxygen_saturation\",\"respiration_rate\",\"stress_level\",\n",
    "        \"predmeal_flag\",\"sleep_stage\",\"minute_of_day\",\"tod_sin\",\"tod_cos\"\n",
    "    ],\n",
    "    futr_exog_list=[\n",
    "        \"activity_steps\",\"calories_value\",\"heartrate\",\n",
    "        \"oxygen_saturation\",\"respiration_rate\",\"stress_level\",\n",
    "        \"predmeal_flag\",\"sleep_stage\",\"minute_of_day\",\"tod_sin\",\"tod_cos\"\n",
    "    ],\n",
    "    stack_types=[\"identity\",\"trend\",\"seasonality\",\"exogenous\"],\n",
    "    n_blocks=[1,1,1,1],\n",
    "    mlp_units=[[512,512]]*4,\n",
    "    max_steps=1000,\n",
    "    learning_rate=1e-3,\n",
    "    early_stop_patience_steps=100\n",
    ")\n",
    "\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq=1    # integer step size of 1\n",
    ")\n",
    "\n",
    "# --- 5) Fit, pointing at your integer‐ds & renames --------------------------\n",
    "\n",
    "# history: everything except the last 12 points per series\n",
    "df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n",
    "# validation: exactly the last 12 points per series\n",
    "df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n",
    "\n",
    "nf.fit(\n",
    "    df=df_hist,\n",
    "    static_df=static_df,\n",
    "    val_size=12,\n",
    "    id_col=\"unique_id\",\n",
    "    time_col=\"ds\",\n",
    "    target_col=\"y\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d4be58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 24/24 [00:00<00:00, 70.49it/s]\n",
      "  unique_id    ds  NBEATSx-lo-60.0  NBEATSx-median  NBEATSx-hi-60.0\n",
      "0      1023  2832       144.194412      147.480042       151.523041\n",
      "1      1023  2833       140.187119      146.592117       153.773026\n",
      "2      1023  2834       136.733170      145.231827       154.601700\n",
      "3      1023  2835       130.639160      141.047485       152.372986\n",
      "4      1023  2836       126.740425      140.055191       152.568039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135555/1348566792.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  out[\"horizon\"] = out.groupby(\"unique_id\").cumcount() + 1\n",
      "/tmp/ipykernel_135555/1348566792.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(\"unique_id\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    unique_id        MAE       RMSE      sMAPE       QL50       QL20  \\\n",
      "0        1023  15.590403  19.171014  10.652983   7.795202   5.477918   \n",
      "1        1024   5.412750   6.568967   5.015932   2.706375   1.338678   \n",
      "2        1026   4.601340   5.764716   3.006143   2.300670   2.970367   \n",
      "3        1027   9.576108  12.888067   3.441846   4.788054   2.158666   \n",
      "4        1028   8.684496   9.291451   7.826418   4.342248   0.554144   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "736      7405   8.004274   8.921197   4.661914   4.002137   0.976972   \n",
      "737      7406  55.465257  60.344473  29.348560  27.732629  15.783017   \n",
      "738      7407  21.340130  25.897581  18.920915  10.670065   6.617842   \n",
      "739      7409   7.756223   9.112579   5.403837   3.878112   1.257435   \n",
      "740      7411  10.707722  11.338146  12.617925   5.353861   4.714882   \n",
      "\n",
      "          QL80  \n",
      "0     4.249460  \n",
      "1     3.094402  \n",
      "2     3.157809  \n",
      "3     4.377191  \n",
      "4     3.770748  \n",
      "..         ...  \n",
      "736   6.500185  \n",
      "737  26.999301  \n",
      "738   4.286251  \n",
      "739   3.620769  \n",
      "740   4.179003  \n",
      "\n",
      "[741 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135555/1348566792.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "futr_template = nf.make_future_dataframe()  # uses the same df_hist under the hood\n",
    "futr_df = futr_template.merge(\n",
    "  df_val.drop(columns=[\"y\"]),\n",
    "  on=[\"unique_id\",\"ds\"],\n",
    "  how=\"left\"\n",
    ")\n",
    "#print(futr_df.head())  # ready to predict on!\n",
    "\n",
    "# 5) Forecast\n",
    "preds = nf.predict(futr_df=futr_df)\n",
    "print(preds.head())\n",
    "\n",
    "# 6) Merge back truth & compute per-horizon metrics\n",
    "out = preds.merge(df_val[[\"unique_id\",\"ds\",\"y\"]], on=[\"unique_id\",\"ds\"])\n",
    "out[\"horizon\"] = out.groupby(\"unique_id\").cumcount() + 1\n",
    "\n",
    "from neuralforecast.losses.numpy import mae, rmse, smape, quantile_loss\n",
    "\n",
    "metrics = (\n",
    "    out\n",
    "    .groupby(\"unique_id\")\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"MAE\":  mae(g[\"y\"], g[\"NBEATSx-median\"]),\n",
    "        \"RMSE\": rmse(g[\"y\"], g[\"NBEATSx-median\"]),\n",
    "        \"sMAPE\":smape(g[\"y\"], g[\"NBEATSx-median\"]) * 100,\n",
    "        \"QL50\": quantile_loss(g[\"y\"], g[\"NBEATSx-median\"], q=0.5),\n",
    "        \"QL20\": quantile_loss(g[\"y\"], g[\"NBEATSx-lo-60.0\"], q=0.2),\n",
    "        \"QL80\": quantile_loss(g[\"y\"], g[\"NBEATSx-hi-60.0\"], q=0.8),\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66d33f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>QL50</th>\n",
       "      <th>QL20</th>\n",
       "      <th>QL80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023</td>\n",
       "      <td>15.590403</td>\n",
       "      <td>19.171014</td>\n",
       "      <td>10.652983</td>\n",
       "      <td>7.795202</td>\n",
       "      <td>5.477918</td>\n",
       "      <td>4.249460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>5.412750</td>\n",
       "      <td>6.568967</td>\n",
       "      <td>5.015932</td>\n",
       "      <td>2.706375</td>\n",
       "      <td>1.338678</td>\n",
       "      <td>3.094402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1026</td>\n",
       "      <td>4.601340</td>\n",
       "      <td>5.764716</td>\n",
       "      <td>3.006143</td>\n",
       "      <td>2.300670</td>\n",
       "      <td>2.970367</td>\n",
       "      <td>3.157809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1027</td>\n",
       "      <td>9.576108</td>\n",
       "      <td>12.888067</td>\n",
       "      <td>3.441846</td>\n",
       "      <td>4.788054</td>\n",
       "      <td>2.158666</td>\n",
       "      <td>4.377191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1028</td>\n",
       "      <td>8.684496</td>\n",
       "      <td>9.291451</td>\n",
       "      <td>7.826418</td>\n",
       "      <td>4.342248</td>\n",
       "      <td>0.554144</td>\n",
       "      <td>3.770748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>7405</td>\n",
       "      <td>8.004274</td>\n",
       "      <td>8.921197</td>\n",
       "      <td>4.661914</td>\n",
       "      <td>4.002137</td>\n",
       "      <td>0.976972</td>\n",
       "      <td>6.500185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>7406</td>\n",
       "      <td>55.465257</td>\n",
       "      <td>60.344473</td>\n",
       "      <td>29.348560</td>\n",
       "      <td>27.732629</td>\n",
       "      <td>15.783017</td>\n",
       "      <td>26.999301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>7407</td>\n",
       "      <td>21.340130</td>\n",
       "      <td>25.897581</td>\n",
       "      <td>18.920915</td>\n",
       "      <td>10.670065</td>\n",
       "      <td>6.617842</td>\n",
       "      <td>4.286251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>7409</td>\n",
       "      <td>7.756223</td>\n",
       "      <td>9.112579</td>\n",
       "      <td>5.403837</td>\n",
       "      <td>3.878112</td>\n",
       "      <td>1.257435</td>\n",
       "      <td>3.620769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>7411</td>\n",
       "      <td>10.707722</td>\n",
       "      <td>11.338146</td>\n",
       "      <td>12.617925</td>\n",
       "      <td>5.353861</td>\n",
       "      <td>4.714882</td>\n",
       "      <td>4.179003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id        MAE       RMSE      sMAPE       QL50       QL20  \\\n",
       "0        1023  15.590403  19.171014  10.652983   7.795202   5.477918   \n",
       "1        1024   5.412750   6.568967   5.015932   2.706375   1.338678   \n",
       "2        1026   4.601340   5.764716   3.006143   2.300670   2.970367   \n",
       "3        1027   9.576108  12.888067   3.441846   4.788054   2.158666   \n",
       "4        1028   8.684496   9.291451   7.826418   4.342248   0.554144   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "736      7405   8.004274   8.921197   4.661914   4.002137   0.976972   \n",
       "737      7406  55.465257  60.344473  29.348560  27.732629  15.783017   \n",
       "738      7407  21.340130  25.897581  18.920915  10.670065   6.617842   \n",
       "739      7409   7.756223   9.112579   5.403837   3.878112   1.257435   \n",
       "740      7411  10.707722  11.338146  12.617925   5.353861   4.714882   \n",
       "\n",
       "          QL80  \n",
       "0     4.249460  \n",
       "1     3.094402  \n",
       "2     3.157809  \n",
       "3     4.377191  \n",
       "4     3.770748  \n",
       "..         ...  \n",
       "736   6.500185  \n",
       "737  26.999301  \n",
       "738   4.286251  \n",
       "739   3.620769  \n",
       "740   4.179003  \n",
       "\n",
       "[741 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac2d3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average MAE, RMSE, sMAPE, QL20, QL80 (remembr that unique_id is a categorical)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume metrics_df is already in the environment with columns:\n",
    "# [\"unique_id\", \"MAE\", \"RMSE\", \"sMAPE\", \"QL20\", \"QL80\"]\n",
    "\n",
    "# Compute mean and 95% confidence intervals for each metric\n",
    "n = len(metrics)\n",
    "z = 1.96  # for 95% CI\n",
    "\n",
    "summary = []\n",
    "for col in [\"MAE\", \"RMSE\", \"sMAPE\", \"QL50\", \"QL20\", \"QL80\"]:\n",
    "    mean_val = metrics[col].mean()\n",
    "    se = metrics[col].std(ddof=1) / np.sqrt(n)\n",
    "    ci_lower = mean_val - z * se\n",
    "    ci_upper = mean_val + z * se\n",
    "    summary.append({\n",
    "        \"metric\": col,\n",
    "        \"mean\": mean_val,\n",
    "        \"ci_lower\": ci_lower,\n",
    "        \"ci_upper\": ci_upper\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ac21d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>11.174004</td>\n",
       "      <td>10.369787</td>\n",
       "      <td>11.978222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>13.083535</td>\n",
       "      <td>12.176872</td>\n",
       "      <td>13.990197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sMAPE</td>\n",
       "      <td>8.215898</td>\n",
       "      <td>7.702068</td>\n",
       "      <td>8.729728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QL50</td>\n",
       "      <td>5.587002</td>\n",
       "      <td>5.184894</td>\n",
       "      <td>5.989111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QL20</td>\n",
       "      <td>3.627929</td>\n",
       "      <td>3.390457</td>\n",
       "      <td>3.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QL80</td>\n",
       "      <td>4.845086</td>\n",
       "      <td>4.401759</td>\n",
       "      <td>5.288414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric       mean   ci_lower   ci_upper\n",
       "0    MAE  11.174004  10.369787  11.978222\n",
       "1   RMSE  13.083535  12.176872  13.990197\n",
       "2  sMAPE   8.215898   7.702068   8.729728\n",
       "3   QL50   5.587002   5.184894   5.989111\n",
       "4   QL20   3.627929   3.390457   3.865400\n",
       "5   QL80   4.845086   4.401759   5.288414"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec88ba",
   "metadata": {},
   "source": [
    "## MODEL 2: DeepAR+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d82ca1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135555/1774965157.py:51: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n",
      "/tmp/ipykernel_135555/1774965157.py:51: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n",
      "/tmp/ipykernel_135555/1774965157.py:52: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n",
      "/tmp/ipykernel_135555/1774965157.py:52: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'cell_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m df_hist \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: g\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m df_val  \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m g: g\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12\u001b[39m:])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mnf_deepar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_hist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# no early-stop slice so last_date aligns with end of history\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munique_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     61\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 3) Build the exact 12-step future grid and merge in df_val\u001b[39;00m\n\u001b[1;32m     64\u001b[0m futr_template \u001b[38;5;241m=\u001b[39m nf_deepar\u001b[38;5;241m.\u001b[39mmake_future_dataframe()\n",
      "File \u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/core.py:562\u001b[0m, in \u001b[0;36mNeuralForecast.fit\u001b[0;34m(self, df, static_df, val_size, use_init_models, verbose, id_col, time_col, target_col, distributed_config, prediction_intervals)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_models()\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels):\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_config\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/common/_base_model.py:1468\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, dataset, val_size, test_size, random_seed, distributed_config)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1441\u001b[0m     dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     distributed_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1446\u001b[0m ):\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit.\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \n\u001b[1;32m   1449\u001b[0m \u001b[38;5;124;03m    The `fit` method, optimizes the neural network's weights using the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;124;03m    `test_size`: int, test size for temporal cross-validation.<br>\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributed_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/neuralforecast/common/_base_model.py:545\u001b[0m, in \u001b[0;36mBaseModel._fit\u001b[0;34m(self, dataset, batch_size, valid_batch_size, val_size, test_size, random_seed, shuffle_train, distributed_config)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[1;32m    544\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 545\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    547\u001b[0m     model\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics\n",
      "File \u001b[0;32m~/miniconda3/envs/cgmall/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'cell_type'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import DeepAR\n",
    "from neuralforecast.utils import AirPassengersDF  # only if you want an example dataset\n",
    "\n",
    "# 0) Prepare your df exactly as before:\n",
    "#    • 'unique_id', 'ds' (int), 'y'\n",
    "#    • all your static, hist_exog_list and futr_exog_list columns\n",
    "\n",
    "# e.g. df = train.rename(…) … cast category dtypes … sort by ['unique_id','ds']\n",
    "\n",
    "# 1) Define your DeepAR model\n",
    "model_deepar = DeepAR(\n",
    "    h=12,                    # forecast 12 steps ahead\n",
    "    input_size=288,          # 12 hrs of 5-min = 288 points context\n",
    "    # how many Monte-Carlo sample trajectories to draw:\n",
    "    trajectory_samples=500,  \n",
    "    #quantiles=[0.2,0.5,0.8], # 3-quantile output\n",
    "    stat_exog_list=[\"age\",\"clinical_site\",\"study_group\"],\n",
    "    # hist_exog_list=[\n",
    "    #   # any covariates you only know historically:\n",
    "    #   \"cgm_lag_1\",\"cgm_lag_3\",\"cgm_lag_6\",\n",
    "    #   \"cgm_diff_lag_1\",\"cgm_diff_lag_3\",\"cgm_diff_lag_6\",\n",
    "    #   \"cgm_lagdiff_1_3\",\"cgm_lagdiff_3_6\",\n",
    "    #   \"cgm_rolling_mean\",\"cgm_rolling_std\",\n",
    "    #   \"activity_steps\",\"calories_value\",\"heartrate\",\n",
    "    #   \"oxygen_saturation\",\"respiration_rate\",\"stress_level\",\n",
    "    #   \"predmeal_flag\",\"sleep_stage\"\n",
    "    # ],\n",
    "    futr_exog_list=[\n",
    "      # covariates you know into the future:\n",
    "      \"minute_of_day\",\"tod_sin\",\"tod_cos\",\n",
    "      \"activity_steps\",\"calories_value\",\"heartrate\",\n",
    "      \"oxygen_saturation\",\"respiration_rate\",\"stress_level\",\n",
    "      \"predmeal_flag\",\"sleep_stage\"\n",
    "    ],\n",
    "    # you can also tune RNN hyper-parameters if you like:\n",
    "    cell_type=\"LSTM\",        # or \"GRU\"\n",
    "    hidden_size=64,          # size of the RNN hidden state\n",
    "    num_layers=2,            # number of RNN layers\n",
    "    dropout=0.1              # dropout on the RNN\n",
    ")\n",
    "\n",
    "# 2) Plug it into a NeuralForecast and fit\n",
    "nf_deepar = NeuralForecast(\n",
    "    models=[model_deepar],\n",
    "    freq=1                  # 5-minute intervals\n",
    ")\n",
    "\n",
    "# If you want to do a manual history/validation split:\n",
    "df_hist = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[:-12]).reset_index(drop=True)\n",
    "df_val  = df.groupby(\"unique_id\", group_keys=False).apply(lambda g: g.iloc[-12:]).reset_index(drop=True)\n",
    "\n",
    "nf_deepar.fit(\n",
    "    df=df_hist,\n",
    "    static_df=static_df,\n",
    "    val_size=0,            # no early-stop slice so last_date aligns with end of history\n",
    "    id_col=\"unique_id\",\n",
    "    time_col=\"ds\",\n",
    "    target_col=\"y\"\n",
    ")\n",
    "\n",
    "# 3) Build the exact 12-step future grid and merge in df_val\n",
    "futr_template = nf_deepar.make_future_dataframe()\n",
    "futr_df = futr_template.merge(\n",
    "    df_val.drop(columns=[\"y\"]),\n",
    "    on=[\"unique_id\",\"ds\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4) Forecast\n",
    "preds_deepar = nf_deepar.predict(futr_df)\n",
    "\n",
    "# preds_deepar will have columns:\n",
    "#   ['unique_id','ds','DeepAR-0.2','DeepAR-0.5','DeepAR-0.8']\n",
    "\n",
    "# 5) Merge back true y and compute any metrics you like\n",
    "out = preds_deepar.merge(df_val[[\"unique_id\",\"ds\",\"y\"]], on=[\"unique_id\",\"ds\"])\n",
    "print(out.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4b31f",
   "metadata": {},
   "source": [
    "## Model 3: PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fd733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14996409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgmall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
